Feature: Feature to validate the lineage created via python spark lineage plugin is correct


  @MLP-8210 @positve @hdfs @regression @sanity @IDA-10.1
  Scenario Outline:SC#2Creating a directory in Ambari Files View and Uploading source files into the directory
    Given configure dynamic endpoint for "<ServiceName>" having multiple header "<Authorization>" "<X-Requested-By>" for request type "<type>" with url "<url>" and body "<body>" and verify "<response code>" and "<response message>"
    Examples:
      | ServiceName  | Authorization              | X-Requested-By | type | url                                                                                                                                                                                                   | body                                                                                   | response code | response message |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Sequence?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                        |                                                                                        | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/NewhadoopFileAPI?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                |                                                                                        | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/HadoopFileAPI?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                   |                                                                                        | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileSpecific_to_saveasHadoopformatandTextFile?op=MKDIRS&recursive=true&overwrite=true                                                                                             |                                                                                        | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile3?op=MKDIRS&recursive=true&overwrite=true                                                                                                                |                                                                                        | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile?op=MKDIRS&recursive=true&overwrite=true                                                                                                                 |                                                                                        | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile2?op=MKDIRS&recursive=true&overwrite=true                                                                                                                |                                                                                        | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Hadoopformat?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                    |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Sequence/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                            | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Sequence/part-00001?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                            | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00001                 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Sequence/part-00002?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                            | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00002                 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Sequence/part-00003?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                            | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00003                 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Hadoopformat/part-r-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                      | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-r-00000               | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Hadoopformat/part-r-00001?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                      | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-r-00001               | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Hadoopformat/part-r-00002?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                      | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-r-00002               | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/Hadoopformat/part-r-00003?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                      | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-r-00003               | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/HadoopFileAPI/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                       | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-00000   | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/HadoopFileAPI/part-00001?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                       | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-00001   | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/NewhadoopFileAPI/part-r-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                  | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00000 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/NewhadoopFileAPI/part-r-00001?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                  | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00001 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/NewhadoopFileAPI/part-r-00002?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                  | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00002 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/NewhadoopFileAPI/part-r-00003?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                  | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00003 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileSpecific_to_saveasHadoopformatandTextFile/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileSpecific_to_saveasHadoopformatandTextFile/part-00001?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00001                 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileSpecific_to_saveasHadoopformatandTextFile/part-00002?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00002                 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileSpecific_to_saveasHadoopformatandTextFile/part-00003?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00003                 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile2/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                    | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-00000   | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile2/part-00001?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                    | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-00001   | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile3/part-r-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                  | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00000 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile3/part-r-00001?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                  | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00001 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile3/part-r-00002?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                  | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00002 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile3/part-r-00003?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                  | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00003 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile/part-r-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                   | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00000 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile/part-r-00001?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                   | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00001 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile/part-r-00002?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                   | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00002 | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/hadoopfileto_saveAsNewHadopFile/part-r-00003?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                   | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/NewhadoopFile/part-r-00003 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/HadoopFile_to_saveAsTextFile?op=MKDIRS&recursive=true&overwrite=true                                                                                                                    |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/HadoopFile_to_saveAsTextFile/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                        | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/NewAPIhadooptoSaveAsNewSequenceFile?op=MKDIRS&recursive=true&overwrite=true                                                                                                             |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/NewAPIhadooptoSaveAsNewSequenceFile/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                 | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/Newhadoopfile_to_SaveAsNewHadoop_pathasVariable?op=MKDIRS&recursive=true&overwrite=true                                                                                                 |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/Newhadoopfile_to_SaveAsNewHadoop_pathasVariable/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true     | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/Newhadoopfileto_saveAsNewHadopFile_withDiffInput?op=MKDIRS&recursive=true&overwrite=true                                                                                                |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/Newhadoopfileto_saveAsNewHadopFile_withDiffInput/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true    | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                    |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                        | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_diffArgs?op=MKDIRS&recursive=true&overwrite=true                                                                                                                           |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_diffArgs/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                               | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_diffFormat?op=MKDIRS&recursive=true&overwrite=true                                                                                                                         |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_diffFormat/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                             | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_file?op=MKDIRS&recursive=true&overwrite=true                                                                                                                               |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_file/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                   | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_multipleRDD?op=MKDIRS&recursive=true&overwrite=true                                                                                                                        |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_multipleRDD/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                            | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_to_Hadoopformat?op=MKDIRS&recursive=true&overwrite=true                                                                                                                    |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_to_Hadoopformat/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                        | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_to_NewHadoopformat1?op=MKDIRS&recursive=true&overwrite=true                                                                                                                |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/SequenceFile_to_NewHadoopformat1/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                    | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopFile_saveAsHadoopFile_Variable?op=MKDIRS&recursive=true&overwrite=true                                                                                                            |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopFile_saveAsHadoopFile_Variable/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfileSpecific_to_saveasHadoopformat?op=MKDIRS&recursive=true&overwrite=true                                                                                                        |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfileSpecific_to_saveasHadoopformat/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true            | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfile_to_saveasHadoopformat?op=MKDIRS&recursive=true&overwrite=true                                                                                                                |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfile_to_saveasHadoopformat/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                    | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfile_to_saveasHadoopformatChangedsavingType?op=MKDIRS&recursive=true&overwrite=true                                                                                               |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfile_to_saveasHadoopformatChangedsavingType/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true   | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfileto_saveAsNewHadopFile?op=MKDIRS&recursive=true&overwrite=true                                                                                                                 |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfileto_saveAsNewHadopFile/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                     | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfileto_saveAsNewHadopFile3?op=MKDIRS&recursive=true&overwrite=true                                                                                                                |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/hadoopfileto_saveAsNewHadopFile3/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                    | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/newHadoopFiletoSaveAsTextFile?op=MKDIRS&recursive=true&overwrite=true                                                                                                                   |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/newHadoopFiletoSaveAsTextFile/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                       | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/newhadoopfile_to_saveasNewHadoopformat_withFormat?op=MKDIRS&recursive=true&overwrite=true                                                                                               |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/newhadoopfile_to_saveasNewHadoopformat_withFormat/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true   | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                                 |                                                                                        | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source1?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                                |                                                                                        | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source2?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                                |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/commands.txt?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                                   | ida/PythonSparkPayloads/pythonSparkLineage_7821_sourceFiles/commands.txt               | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source/spark.csv?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                                      | ida/PythonSparkPayloads/pythonSparkLineage_7821_sourceFiles/spark.csv                  | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source1/optimized3.orc?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                                | ida/PythonSparkPayloads/pythonSparkLineage_7821_sourceFiles/optimzed3.orc              | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source1/spark3.csv?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                                    | ida/PythonSparkPayloads/pythonSparkLineage_7821_sourceFiles/spark.csv                  | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source1/users4.parquet?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                                | ida/PythonSparkPayloads/pythonSparkLineage_7821_sourceFiles/users4.parquet             | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source2/optimized2.orc?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                                | ida/PythonSparkPayloads/pythonSparkLineage_7821_sourceFiles/optimzed2.orc              | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source2/spark.csv?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                                     | ida/PythonSparkPayloads/pythonSparkLineage_7821_sourceFiles/spark.csv                  | 201           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/source2/users3.parquet?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                                | ida/PythonSparkPayloads/pythonSparkLineage_7821_sourceFiles/users3.parquet             | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target1/sid/csvFile.csv?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target1/sid/csvFile.csv/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                    | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target2/sid/WholeDirectory.json?op=MKDIRS&recursive=true&overwrite=true                                                                                                                        |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target2/sid/WholeDirectory.json/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                            | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target3?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                                |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target3/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                                    | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/sid/textFile.txt?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/sid/textFile.txt/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                    | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/sid/textFile?op=MKDIRS&recursive=true&overwrite=true                                                                                                                                    |                                                                                        | 200           |                  |
      | HdfsDataNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Put  | python/Target/sid/textFile/part-00000?user.name=raj_ops&op=CREATE&namenoderpcaddress=sandbox.hortonworks.com:8020&createflag=&createparent=true&overwrite=true                                        | ida/PythonSparkPayloads/pythonSparkLineage_8210_sourceFiles/part-00000                 | 201           |                  |

  @sanity @positive @regression @IDA_E2E
  Scenario Outline: SC#1:Create Business Application tag for Java Spark Lineage test for HDFS Datasource
    Given endpoint for "<ServiceName>" for "<ServiceUser>" having "<Header>" and query param with "<Query>" "<Param>" for request type "<type>" with url "<url>" and body "<body>" and verify "<response code>" and "<response message>" using "<jsonPath>"
    Examples:
      | ServiceName | ServiceUser    | Header           | Query | Param | type | url                | body                                                 | response code | response message | jsonPath |
      | IDC         | TestSystemUser | application/json |       |       | Post | items/Default/root | ida/PythonSparkPayloads/hdfs/BA_PythonSparkHDFS.json | 200           |                  |          |

  @sanity @positive @regression
  Scenario: SC#1:MLP_24889_Update the Host name respect to the docker
    And user update json file "ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSDataSources.json" file for following values using property loader
      | jsonPath                                           | jsonValues      |
      | $.hdfsDataSource.clusterManager.clusterManagerHost | clusterHostName |


  @sanity @positive @regression
  Scenario Outline: SC#1: Set the Credentials and Datasources for Git and HDFS
    Given endpoint for "<ServiceName>" for "<ServiceUser>" having "<Header>" and query param with "<Query>" "<Param>" for request type "<type>" with url "<url>" and body as string from "<bodyFile>" with "<path>" and verify "<response code>" and "<response message>" using "<jsonPath>"
    Examples:
      | ServiceName | ServiceUser    | Header           | Query | Param | type | url                                                              | bodyFile                                                                           | path                     | response code | response message       | jsonPath |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/credentials/Git_Credentials                             | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSCredentials.json | $.gitCredentials         | 200           |                        |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/credentials/HdfsCredentials                             | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSCredentials.json | $.hdfsCredentials        | 200           |                        |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/analyzers/GitCollectorDataSource/GitCollectorDataSource | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSDataSources.json | $.gitCollectorDataSource | 204           |                        |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/analyzers/HdfsDataSource/HdfsDataSource                 | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSDataSources.json | $.hdfsDataSource         | 204           |                        |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Get  | settings/analyzers/GitCollectorDataSource/GitCollectorDataSource |                                                                                    |                          | 200           | GitCollectorDataSource |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Get  | settings/analyzers/HdfsDataSource/HdfsDataSource                 |                                                                                    |                          | 200           | HdfsDataSource         |          |

  ############################################# Plugin Run ##########################################################
  @javaspark @MLP-10515
  Scenario Outline: SC#2-Configurations for Plugins - Git, HDFS Cataloger, Java Parser and Java Spark Lineage
    Given endpoint for "<ServiceName>" for "<ServiceUser>" having "<Header>" and query param with "<Query>" "<Param>" for request type "<type>" with url "<url>" and body as string from "<bodyFile>" with "<path>" and verify "<response code>" and "<response message>" using "<jsonPath>"
    Examples:
      | ServiceName | ServiceUser    | Header           | Query | Param | type | url                                                      | bodyFile                                                                             | path                 | response code | response message   | jsonPath |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/analyzers/HdfsCataloger/HdfsCataloger           | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSPluginConfigs.json | $.hdfsCataloger      | 204           |                    |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Get  | settings/analyzers/HdfsCataloger/HdfsCataloger           |                                                                                      |                      | 200           | HdfsCataloger      |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/analyzers/GitCollector/GitCollector1            | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSPluginConfigs.json | $.gitCollector1      | 204           |                    |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Get  | settings/analyzers/GitCollector/GitCollector1            |                                                                                      |                      | 200           | GitCollector1      |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/analyzers/GitCollector/GitCollector2            | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSPluginConfigs.json | $.gitCollector2      | 204           |                    |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Get  | settings/analyzers/GitCollector/GitCollector2            |                                                                                      |                      | 200           | GitCollector2      |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/analyzers/GitCollector/GitCollector3            | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSPluginConfigs.json | $.gitCollector3      | 204           |                    |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Get  | settings/analyzers/GitCollector/GitCollector3            |                                                                                      |                      | 200           | GitCollector3      |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/analyzers/GitCollector/GitCollector4            | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSPluginConfigs.json | $.gitCollector4      | 204           |                    |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Get  | settings/analyzers/GitCollector/GitCollector4            |                                                                                      |                      | 200           | GitCollector4      |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/analyzers/PythonParser/PythonParser             | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSPluginConfigs.json | $.pythonParser       | 204           |                    |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Get  | settings/analyzers/PythonParser/PythonParser             |                                                                                      |                      | 200           | PythonParser       |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Put  | settings/analyzers/PythonSparkLineage/PythonSparkLineage | payloads/ida/PythonSparkPayloads/hdfs/PluginConfig/pythonSparkHDFSPluginConfigs.json | $.pythonSparkLineage | 204           |                    |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Get  | settings/analyzers/PythonSparkLineage/PythonSparkLineage |                                                                                      |                      | 200           | PythonSparkLineage |          |

  @javaspark @MLP-10515
  Scenario Outline: SC#2-Run the Plugin configurations for Git, HDFS Cataloger, Java Parser, Java Linker and JavaJDBCLineage
    Given endpoint for "<ServiceName>" for "<ServiceUser>" having "<Header>" and query param with "<Query>" "<Param>" for request type "<type>" with url "<url>" and body "<body>" and verify "<response code>" and "<response message>" using "<jsonPath>"
    Examples:
      | ServiceName | ServiceUser    | Header           | Query | Param | type         | url                                                                                 | body           | response code | response message | jsonPath                                                |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/collector/GitCollector/GitCollector1          |                | 200           | IDLE             | $.[?(@.configurationName=='GitCollector1')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | Post         | extensions/analyzers/start/LocalNode/collector/GitCollector/GitCollector1           | ida/empty.json | 200           |                  |                                                         |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/collector/GitCollector/GitCollector1          |                | 200           | IDLE             | $.[?(@.configurationName=='GitCollector1')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/collector/GitCollector/GitCollector2          |                | 200           | IDLE             | $.[?(@.configurationName=='GitCollector2')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | Post         | extensions/analyzers/start/LocalNode/collector/GitCollector/GitCollector2           | ida/empty.json | 200           |                  |                                                         |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/collector/GitCollector/GitCollector2          |                | 200           | IDLE             | $.[?(@.configurationName=='GitCollector2')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/collector/GitCollector/GitCollector3          |                | 200           | IDLE             | $.[?(@.configurationName=='GitCollector3')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | Post         | extensions/analyzers/start/LocalNode/collector/GitCollector/GitCollector3           | ida/empty.json | 200           |                  |                                                         |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/collector/GitCollector/GitCollector3          |                | 200           | IDLE             | $.[?(@.configurationName=='GitCollector3')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/collector/GitCollector/GitCollector4          |                | 200           | IDLE             | $.[?(@.configurationName=='GitCollector4')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | Post         | extensions/analyzers/start/LocalNode/collector/GitCollector/GitCollector4           | ida/empty.json | 200           |                  |                                                         |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/collector/GitCollector/GitCollector4          |                | 200           | IDLE             | $.[?(@.configurationName=='GitCollector4')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/Cluster%20Demo/cataloger/HdfsCataloger/HdfsCataloger    |                | 200           | IDLE             | $.[?(@.configurationName=='HdfsCataloger')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | Post         | extensions/analyzers/start/Cluster%20Demo/cataloger/HdfsCataloger/HdfsCataloger     | ida/empty.json | 200           |                  |                                                         |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/Cluster%20Demo/cataloger/HdfsCataloger/HdfsCataloger    |                | 200           | IDLE             | $.[?(@.configurationName=='HdfsCataloger')].status      |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/parser/PythonParser/PythonParser              |                | 200           | IDLE             | $.[?(@.configurationName=='PythonParser')].status       |
      | IDC         | TestSystemUser | application/json | raw   | false | Post         | extensions/analyzers/start/LocalNode/parser/PythonParser/PythonParser               | ida/empty.json | 200           |                  |                                                         |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/parser/PythonParser/PythonParser              |                | 200           | IDLE             | $.[?(@.configurationName=='PythonParser')].status       |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/lineage/PythonSparkLineage/PythonSparkLineage |                | 200           | IDLE             | $.[?(@.configurationName=='PythonSparkLineage')].status |
      | IDC         | TestSystemUser | application/json | raw   | false | Post         | extensions/analyzers/start/LocalNode/lineage/PythonSparkLineage/PythonSparkLineage  | ida/empty.json | 200           |                  |                                                         |
      | IDC         | TestSystemUser | application/json | raw   | false | RecursiveGet | extensions/analyzers/status/LocalNode/lineage/PythonSparkLineage/PythonSparkLineage |                | 200           | IDLE             | $.[?(@.configurationName=='PythonSparkLineage')].status |



    ####################### API Lineage verification #############################################
  @javaspark @MLP-10515 @regression @positive
  Scenario Outline:SC#3:API Lineage ID retrieval: user connects to database and retrieves Lineage Hops Ids in order to find Source and Target Data
    Given user connects "<database>" and "<retrive>" by running query with "<catalog>""<type>""<name>""<asg_scopeid>" and store the item id results in "<targetFile>" using "<jsonpath>"
    Examples:
      | database      | retrive    | catalog | type       | name                                                       | asg_scopeid | targetFile                                                                                                          | jsonpath     |
      | APPDBPOSTGRES | ClassID    | Default | Class      | RandomCheck_Flow                                           |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/RandomCheck_Flow.json                                           |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/RandomCheck_Flow.json                                           |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/RandomCheck_Flow.json                                           | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | Negative_Flow                                              |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/Negative_Flow.json                                              |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example2                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/Negative_Flow.json                                              |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/Negative_Flow.json                                              | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | Positive_Flow                                              |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/Positive_Flow.json                                              |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/Positive_Flow.json                                              |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/Positive_Flow.json                                              | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | seqtoHadoop_API                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/seqtoHadoop_API.json                                            |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/seqtoHadoop_API.json                                            |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/seqtoHadoop_API.json                                            | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | SaveAsSequenceFile_API                                     |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/SaveAsSequenceFile_API.json                                     |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/SaveAsSequenceFile_API.json                                     |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/SaveAsSequenceFile_API.json                                     | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | DiffFileFormat                                             |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DiffFileFormat.json                                             |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DiffFileFormat.json                                             |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DiffFileFormat.json                                             | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | DifferentArguments                                         |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DifferentArguments.json                                         |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DifferentArguments.json                                         |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DifferentArguments.json                                         | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | NewHadoopFile_API                                          |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFile_API.json                                          |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example2                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFile_API.json                                          |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFile_API.json                                          | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | DifferentFormat                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DifferentFormat.json                                            |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DifferentFormat.json                                            |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DifferentFormat.json                                            | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | hadooptosaveAsHadoopFiletoFile                             |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/hadooptosaveAsHadoopFiletoFile.json                             |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/hadooptosaveAsHadoopFiletoFile.json                             |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/hadooptosaveAsHadoopFiletoFile.json                             | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | HadoopFileToSaveasHadoopFilewithfileFormat                 |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFileToSaveasHadoopFilewithfileFormat.json                 |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFileToSaveasHadoopFilewithfileFormat.json                 |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFileToSaveasHadoopFilewithfileFormat.json                 | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat.json |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat.json |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat.json | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | HadooptoNewHadoopFile                                      |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadooptoNewHadoopFile.json                                      |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadooptoNewHadoopFile.json                                      |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadooptoNewHadoopFile.json                                      | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | HadoopFilePathinVariable                                   |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFilePathinVariable.json                                   |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example2                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFilePathinVariable.json                                   |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFilePathinVariable.json                                   | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | Hadoop_diffInputType                                       |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/Hadoop_diffInputType.json                                       |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/Hadoop_diffInputType.json                                       |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/Hadoop_diffInputType.json                                       | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | NewHadoopFilediffInputType                                 |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFilediffInputType.json                                 |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFilediffInputType.json                                 |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFilediffInputType.json                                 | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | NewHadooptosaveAsNewHadoopFile                             |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadooptosaveAsNewHadoopFile.json                             |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadooptosaveAsNewHadoopFile.json                             |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadooptosaveAsNewHadoopFile.json                             | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath    |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath.json    |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath.json    |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath.json    | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | NewhadooptosaveAsNewHadoopwithpath                         |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewhadooptosaveAsNewHadoopwithpath.json                         |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewhadooptosaveAsNewHadoopwithpath.json                         |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewhadooptosaveAsNewHadoopwithpath.json                         | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | NewHadoopFiletoSaveAsTextFile                              |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFiletoSaveAsTextFile.json                              |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example2                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFiletoSaveAsTextFile.json                              |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFiletoSaveAsTextFile.json                              | $.functionID |
      | APPDBPOSTGRES | ClassID    | Default | Class      | NewHadoopFilediffFormat                                    |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFilediffFormat.json                                    |              |
      | APPDBPOSTGRES | FunctionID | Default |            | basic_datasource_example1                                  |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFilediffFormat.json                                    |              |
      | APPDBPOSTGRES | LineageID  | Default | LineageHop |                                                            |             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFilediffFormat.json                                    | $.functionID |


  @javaspark @MLP-10515 @regression @positive
  Scenario Outline: SC#3:API Lineage From To retrieval: User retrieves the  Lineage From and Lineage To data for lineage hop ids
    Given A query param with "" and "" and supply authorized users, contentType and Accept headers
    And user get source and target name from REST "<url>" for each "<item>" lineage hop ids from "<inputFile>" and store source and target  name in "<outputFile>"
    Examples:
      | url                                                                      | item                                                       | inputFile                                                                                                           | outputFile                                                                                  |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | RandomCheck_Flow                                           | response/python/pythonSpark/pythonSparkHDFS/Lineage/RandomCheck_Flow.json                                           | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | Negative_Flow                                              | response/python/pythonSpark/pythonSparkHDFS/Lineage/Negative_Flow.json                                              | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | Positive_Flow                                              | response/python/pythonSpark/pythonSparkHDFS/Lineage/Positive_Flow.json                                              | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | seqtoHadoop_API                                            | response/python/pythonSpark/pythonSparkHDFS/Lineage/seqtoHadoop_API.json                                            | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | SaveAsSequenceFile_API                                     | response/python/pythonSpark/pythonSparkHDFS/Lineage/SaveAsSequenceFile_API.json                                     | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | DiffFileFormat                                             | response/python/pythonSpark/pythonSparkHDFS/Lineage/DiffFileFormat.json                                             | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | DifferentArguments                                         | response/python/pythonSpark/pythonSparkHDFS/Lineage/DifferentArguments.json                                         | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | NewHadoopFile_API                                          | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFile_API.json                                          | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | DifferentFormat                                            | response/python/pythonSpark/pythonSparkHDFS/Lineage/DifferentFormat.json                                            | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | hadooptosaveAsHadoopFiletoFile                             | response/python/pythonSpark/pythonSparkHDFS/Lineage/hadooptosaveAsHadoopFiletoFile.json                             | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | HadoopFileToSaveasHadoopFilewithfileFormat                 | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFileToSaveasHadoopFilewithfileFormat.json                 | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat.json | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | HadooptoNewHadoopFile                                      | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadooptoNewHadoopFile.json                                      | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | HadoopFilePathinVariable                                   | response/python/pythonSpark/pythonSparkHDFS/Lineage/HadoopFilePathinVariable.json                                   | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | Hadoop_diffInputType                                       | response/python/pythonSpark/pythonSparkHDFS/Lineage/Hadoop_diffInputType.json                                       | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | NewHadoopFilediffInputType                                 | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFilediffInputType.json                                 | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | NewHadooptosaveAsNewHadoopFile                             | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadooptosaveAsNewHadoopFile.json                             | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath    | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath.json    | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | NewhadooptosaveAsNewHadoopwithpath                         | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewhadooptosaveAsNewHadoopwithpath.json                         | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | NewHadoopFiletoSaveAsTextFile                              | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFiletoSaveAsTextFile.json                              | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |
      | searches/Default/query/queryDiagramOutRecursive/Default.LineageHop:::DYN | NewHadoopFilediffFormat                                    | response/python/pythonSpark/pythonSparkHDFS/Lineage/NewHadoopFilediffFormat.json                                    | response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json |


  @javaspark @MLP-10515 @regression @positive
  Scenario Outline: SC#3:API Lineage Hops Final Validation: Lineage Hops Final Validation using API
    Given expected JSON "<expected_json>" data should be equal to actual "<actual_json>" data for item "<item>"
    Examples:
      | expected_json                                                                    | actual_json                                                                                                   | item                                                       |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | RandomCheck_Flow                                           |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | Negative_Flow                                              |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | Positive_Flow                                              |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | seqtoHadoop_API                                            |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | SaveAsSequenceFile_API                                     |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | DiffFileFormat                                             |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | DifferentArguments                                         |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | NewHadoopFile_API                                          |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | DifferentFormat                                            |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | hadooptosaveAsHadoopFiletoFile                             |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | HadoopFileToSaveasHadoopFilewithfileFormat                 |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | HadooptoNewHadoopFile                                      |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | HadoopFilePathinVariable                                   |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | Hadoop_diffInputType                                       |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | NewHadoopFilediffInputType                                 |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | NewHadooptosaveAsNewHadoopFile                             |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath    |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | NewhadooptosaveAsNewHadoopwithpath                         |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | NewHadoopFiletoSaveAsTextFile                              |
      | ida/PythonSparkPayloads/hdfs/LineageMetadata/expectedPythonSparkLineageHDFS.json | Constant.REST_DIR/response/python/pythonSpark/pythonSparkHDFS/Lineage/PythonSparkLineageHDFSSourceTarget.json | NewHadoopFilediffFormat                                    |


############################################################################################################################################################################
###################Deleting the catalog , plugins configurations and Target folders from HDFS
###################################################################################################################################################################

  @MLP-8210 @positve @hdfs @regression @positive @sanity @IDA-10.2
  Scenario Outline:Scenario Outline: Delete the created files in Ambari
    Given configure dynamic endpoint for "<ServiceName>" having multiple header "<Authorization>" "<X-Requested-By>" for request type "<type>" with url "<url>" and body "<body>" and verify "<response code>" and "<response message>"
    Examples:
      | ServiceName  | Authorization              | X-Requested-By | type   | url                                     | body | response code | response message |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Delete | python/source?op=DELETE&recursive=true  |      | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Delete | python/Target?op=DELETE&recursive=true  |      | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Delete | python/source1?op=DELETE&recursive=true |      | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Delete | python/source2?op=DELETE&recursive=true |      | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Delete | python/Target1?op=DELETE&recursive=true |      | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Delete | python/Target2?op=DELETE&recursive=true |      | 200           |                  |
      | HdfsNameNode | Basic cmFqX29wczpyYWpfb3Bz | ambari         | Delete | python/Target3?op=DELETE&recursive=true |      | 200           |                  |

  @cr-data @postcondition @sanity @positive
  Scenario: Post Conditions: ItemDeletion- User deletes the collected item from database using dynamic id stored in json
    Given Delete multiple values in IDC UI with below parameters
      | deleteAction     | catalog | name                                           | type                | query | param |
      | SingleItemDelete | Default | Cluster Demo                                   | Cluster             |       |       |
      | SingleItemDelete | Default | pythonanalyzerdemo                             | Project             |       |       |
      | SingleItemDelete | Default | test_BA_PythonSparkHDFS                        | BusinessApplication |       |       |
      | MultipleIDDelete | Default | collector/GitCollector/GitCollector1%          | Analysis            |       |       |
      | MultipleIDDelete | Default | collector/GitCollector/GitCollector2%          | Analysis            |       |       |
      | MultipleIDDelete | Default | collector/GitCollector/GitCollector3%          | Analysis            |       |       |
      | MultipleIDDelete | Default | collector/GitCollector/GitCollector4%          | Analysis            |       |       |
      | MultipleIDDelete | Default | cataloger/HdfsCataloger/HdfsCataloger%         | Analysis            |       |       |
      | MultipleIDDelete | Default | parser/PythonParser/PythonParser%              | Analysis            |       |       |
      | MultipleIDDelete | Default | lineage/PythonSparkLineage/PythonSparkLineage% | Analysis            |       |       |

  @cr-data @postcondition @sanity @positive
  Scenario Outline: Post Conditions: ConfigDeletion: Delete the Plugin configurations for Git, HDFS Cataloger, Python Parser and Python Spark Lineage
    Given endpoint for "<ServiceName>" for "<ServiceUser>" having "<Header>" and query param with "<Query>" "<Param>" for request type "<type>" with url "<url>" and body "<body>" and verify "<response code>" and "<response message>" using "<jsonPath>"
    Examples:
      | ServiceName | ServiceUser    | Header           | Query | Param | type   | url                                                              | body | response code | response message | jsonPath |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/credentials/Git_Credentials                             |      | 200           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/credentials/HdfsCredentials                             |      | 200           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/analyzers/GitCollectorDataSource/GitCollectorDataSource |      | 204           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/analyzers/GitCollector/GitCollector1                    |      | 204           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/analyzers/GitCollector/GitCollector2                    |      | 204           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/analyzers/GitCollector/GitCollector3                    |      | 204           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/analyzers/GitCollector/GitCollector4                    |      | 204           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/analyzers/HdfsDataSource/HdfsDataSource                 |      | 204           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/analyzers/HdfsCataloger/HdfsCataloger                   |      | 204           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/analyzers/PythonParser/PythonParser                     |      | 204           |                  |          |
      | IDC         | TestSystemUser | application/json | raw   | false | Delete | settings/analyzers/PythonSparkLineage/PythonSparkLineage         |      | 204           |                  |          |


#
#The Following Steps are commented as these are step definctions to actually run the Spark Program units to generate Targets.  Now, as the source and targets are added automatically without the need of running Spark Program code, they are commented. (They are still in Feature file just for Future references)
#

##
#  @MLP-8210 @sanity @hdfs @regression @positive
#  Scenario:Moving the file from local to the folder in Ambari
#    Given user connects to the SFTP server for below parameters
#      | sftpHost        | sftpPort       | sftpUser     | sftpPw       | sftpAction | remoteDir | localDir                                             |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_SeqtosaveAsSeq/SaveAsSequenceFile_API.py                                              |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_SeqtosaveAsSeq/DiffFileFormat.py                                                      |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_SeqtosaveAsSeq/DifferentFormat.py                                                     |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_SeqtosaveAsSeq/DifferentArguments.py                                                  |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_SeqtosaveAsSeq/seqtoHadoop_API.py                                                     |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_SeqtosaveAsSeq/NewHadoopFile_API.py                                                   |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_hadooptoSaveAsHadoop/hadooptosaveAsHadoopFiletoFile.py                                |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_hadooptoSaveAsHadoop/HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat.py    |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_hadooptoSaveAsHadoop/HadoopFilePathinVariable.py                                      |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_hadooptoSaveAsHadoop/HadoopFileToSaveasHadoopFilewithfileFormat.py                    |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_hadooptoSaveAsHadoop/HadooptoNewHadoopFile.py                                         |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_hadooptoSaveAsHadoop/Hadoop_diffInputType.py                                          |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_NewhadooptoSaveAsNewHadoop/NewHadoopFilediffFormat.py                                 |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_NewhadooptoSaveAsNewHadoop/NewHadoopFilediffInputType.py                              |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_NewhadooptoSaveAsNewHadoop/NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath.py |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_NewhadooptoSaveAsNewHadoop/NewHadoopFiletoSaveAsTextFile.py                           |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_NewhadooptoSaveAsNewHadoop/NewHadooptosaveAsNewHadoopFile.py                          |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-8210_NewhadooptoSaveAsNewHadoop/NewhadooptosaveAsNewHadoopwithpath.py                      |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-7821/Negative_Flow.py    |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-7821/Positive_Flow.py    |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | copyFiles  | /root     | ida/PythonSparkPayloads/MLP-7821/RandomCheck_Flow.py |

#
#
#  @MLP-8210 @sanity @positive @regression @hbase @sftp
#  Scenario: Configuring and Running Spark Commands
#    And user connects to the sftp server and runs spark commands
#      | command | Filename            |
#      | SPARK2  | seqtoHadoop_API.py                                            |
#      | SPARK2  | SaveAsSequenceFile_API.py                                     |
#      | SPARK2  | DifferentFormat.py                                            |
#      | SPARK2  | DiffFileFormat.py                                             |
#      | SPARK2  | DifferentArguments.py                                         |
#      | SPARK2  | NewHadoopFile_API.py                                          |
#      | SPARK2  | hadooptosaveAsHadoopFiletoFile.py                             |
#      | SPARK2  | HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat.py |
#      | SPARK2  | HadoopFilePathinVariable.py                                   |
#      | SPARK2  | HadoopFileToSaveasHadoopFilewithfileFormat.py                 |
#      | SPARK2  | HadooptoNewHadoopFile.py                                      |
#      | SPARK2  | Hadoop_diffInputType.py                                       |
#      | SPARK2  | NewHadoopFilediffFormat.py                                    |
#      | SPARK2  | NewHadoopFilediffInputType.py                                 |
#      | SPARK2  | NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath.py    |
#      | SPARK2  | NewHadoopFiletoSaveAsTextFile.py                              |
#      | SPARK2  | NewHadooptosaveAsNewHadoopFile.py                             |
#      | SPARK2  | NewhadooptosaveAsNewHadoopwithpath.py                         |
#      | SPARK2  | RandomCheck_Flow.py |
#      | SPARK2  | Positive_Flow.py    |
#      | SPARK2  | Negative_Flow.py    |


#  @MLP-8210 @sanity @hdfs @regression @positive
#  Scenario:Deleting the file from root folder in Ambari
#    Given user connects to the SFTP server for below parameters
#      | sftpHost        | sftpPort       | sftpUser     | sftpPw       | sftpAction  | localDir | remoteDir                                                     |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | SaveAsSequenceFile_API.py                                     |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | DiffFileFormat.py                                             |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | DifferentFormat.py                                            |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | DifferentArguments.py                                         |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | seqtoHadoop_API.py                                            |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | NewHadoopFile_API.py                                          |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | hadooptosaveAsHadoopFiletoFile.py                             |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | HadoopFileToSaveasSequenceFileandSaveAsTextFile_diffFormat.py |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | HadoopFilePathinVariable.py                                   |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | HadoopFileToSaveasHadoopFilewithfileFormat.py                 |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | HadooptoNewHadoopFile.py                                      |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | Hadoop_diffInputType.py                                       |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | NewHadoopFilediffFormat.py                                    |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | NewHadoopFilediffInputType.py                                 |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | NewHadoopFileToSaveasNewHadoopFileSourceandTargetinpath.py    |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | NewHadoopFiletoSaveAsTextFile.py                              |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | NewHadooptosaveAsNewHadoopFile.py                             |
#      | clusterHostName | sftpPortNumber | sftpUsername | sftpPassword | deleteFiles | /root    | NewhadooptosaveAsNewHadoopwithpath.py                         |
